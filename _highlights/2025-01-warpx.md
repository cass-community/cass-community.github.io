---
title: WarpX Enables Computational Design of Next-Generation Plasma-Based Accelerators
date: 2025-01-21
teaser: 2025-01-warpx/warpx-amrex.png
software_mentioned:
  - AMReX
  - MAGMA
  - libEnsemble
  - xSDK
  - Spack
  - E4S
  - HDF5
  - ADIOS
  - ParaView
  - ParaView Catalyst
  - Ascent
  - VisIt
  - VTK-m
  - MPICH
  - Open MPI
  - Darshan
  - HPCToolkit
  - TAU
  - PAPI
  - Dyninst
#
cass_members:
  - FASTMath
  - PESO
  - RAPIDS
  - S4PST
  - STEP
#
# The excerpt is used on the main Impacts page.
# The heading at the beginning of the body messes up the automatic excerpting process.
#  
excerpt: WarpX is a particle-in-cell (PIC) simulation code that models the motion of charged particles or plasma. WarpX is used to model chains of plasma-based particle accelerators for future high-energy physics colliders – table-top particle accelerators. These table-top accelerators can be used in both scientific and medical applications.
---
{% comment %}
  Questions for Jean-Luc Vay

  * Can you help us strengthen the science impact aspect of this highlight -- perhaps expanding the first paragraph, or even adding a second paragraph?  Links to papers with specific scientific higlights can be included.

  * In the enabling software section, is there anything that shouldn't be included (e.g., WarpX isn't actually using)?
  * Is there any software in the CASS software catalog (https://cass.community/new/software/) that we should add to the highlight?
  * Are any changes needed to the way we describe the software and WarpX's use of it?  Is there anything additional we can say about how software products added features or made other enhancements to better support WarpX?

  * In the Development tools section, we've listed all of the performance tools in the CASS software catalog.  Do you know the details of which ones your team *actually* uses in performance analysis and optimization?  Because of the nature of this site, we're not looking for software that's not already listed here.  But if you *are* using any of these, it would be nice to be more specific here.

{% endcomment %}
## The science

[WarpX](https://ecp-warpx.github.io/) is a particle-in-cell (PIC) simulation code that models the motion of charged particles or plasma.  WarpX is used to model chains of plasma-based particle accelerators for future high-energy physics colliders -- table-top particle accelerators.  These table-top accelerators can be used in both scientific and medical applications.  

WarpX was the 2022 winner of the Association for Computer Machinery (ACM) [Gordon Bell Prize](https://awards.acm.org/bell), a prestigious award recognizing outstanding achievement in high performance computing, requiring scientific innovation, innovation in the software implementation, and high performance.  ([WarpX Gordon Bell citation](https://doi.org/10.1109/SC41404.2022.00008)).

## The enabling software

WarpX relies on a wide range of other software to deliver its scientific capabilities.  The following highlights software from the CASS scientific software ecosystem used by WarpX.  

### Mathematical libraries (FASTMath)

{% capture img %}{% include hl-image-path image="2025-01-warpx/warpx-amrex.png" %}{% endcapture %}
{% include figure class="align-right" width="50%" popup=true image_path=img alt="Image showing a laser wakefield acceleration" caption="Impact of AMReX integration with WarpX: Simulation of laser wakefield acceleration performed with WarpX. The laser pulse propagates from left to right in a uniform plasma. A moving window is used, i.e. the simulation box travels at the speed of light to follow the laser pulse. The central slice of plasma electrons is shown as transparent white dots. A cavity free of plasma electrons forms in the laser wake, where an electron bunch (solid white dots) is accelerated. The colormap shows the longitudinal electric field in the wake. The white box in the center shows the mesh-refined area.  Image courtesy of Maxence Thévenet & the WarpX team.  Description from [AMReX image gallery](https://amrex-codes.github.io/amrex/gallery.html)." %}

WarpX utilizes a number of mathematical libraries and related tools, including **AMReX** for adaptive mesh refinement capabilities, **MAGMA** for GPU-enabled BLAS and LAPACK capabilities, and **libEnsemble** for parameter studies.  These libraries are part of the **xSDK** Extreme-Scale Scientific Software Development Kit, which provides enhanced interoperability among member libraries, making it easier for WarpX to incorporate additional numerical libraries when needed for future developments.

### Software ecosystem and delivery (PESO)

The WarpX team relies on **Spack** to build the application as well as its many dependencies ([WarpX Spack package](https://packages.spack.io/package.html?name=warpx)) in a coordinated fashion.  Moreover, WarpX, along with its dependencies, are part of the **E4S** software distribution ([WarpX in the E4S documentation portal](https://e4s-project.github.io/DocPortal.html?search=WARPX)), allowing developers and users to take advantage of benefits such as build caches, pre-built containers, and installations at a variety of HPC facilities.

### Data and visualization (RAPIDS)

WarpX supports many different output file formats, including VTK visualization files and OpenPMD-compatible I/O, which is a standardized metadata naming convention for particle-mesh data files.  WarpX leverages both **HDF5** and **ADIOS** I/O libraries to support these various formats. ADIOS added OpenMP and BP capabilities specifically to support WarpX.

{% capture img1 %}{% include hl-image-path image="2025-01-warpx/ez-slice_paraview.png" %}{% endcapture %}
{% capture img2 %}{% include hl-image-path image="2025-01-warpx/bx-slice_paraview.png" %}{% endcapture %}
{% include figure2 class="align-right" width="50%"
  popup1=true image_path1=img1 alt="Images showing electric field in a WarpX simulation"
  popup2=true image_path2=img2 alt="Images showing magnetic field in a WarpX simulation"
  caption="z-component of the electric field (top) and x-component of the magnetic field (bottom) in a WarpX data set using ParaView in client server mode on the OLCF Crusher machine (precursor to Frontier) using 96 nodes and ParaView 5.11.0 deployed with Spack." %}

WarpX also has a broad base of users who use a variety of different tools to visualize and analyze the results of their simulations.  Many of these products have been enhanced to better support WarpX, e.g., through adding readers to support the various WarpX I/O formats.

**ParaView** is a widely-used open-source post-processing visualization application, enabling WarpX users to visualize, analyze and explore simulation data.  ParaView's GPU capabilities benefit users such as WarpX.  ParaView specifically developed an OpenPMD reader for WarpX. WarpX has also integrated **Catalyst**, ParaView's API for in situ visualization to allow visualization and analysis tasks to execute while the simulation is running instead of having to wait until the simulation ends.

{% capture img %}{% include hl-image-path image="2025-01-warpx/ascent-warpx.png" %}{% endcapture %}
{% include figure class="align-right" width="50%" popup=true image_path=img alt="Images showing pulse of electrons in an electric fields in a WarpX simulation" caption="A pulse of electrons (small yellowish blob) moves through the electric field in a laser-accelerated wake field from the WarpX simulation, integrated with Ascent." %}

**Ascent** is another lightweight in situ visualization framework which WarpX has integrated with their code.  WarpX was an early user of the Ascent Replay capability which allows a simulation code to easily and cheaply develop its visualization pipeline on low resolution data before running at high resolution.  

{% capture img %}{% include hl-image-path image="2025-01-warpx/visit-warpx.png" %}{% endcapture %}
{% include figure class="align-right" width="50%" popup=true image_path=img alt="Image showing electric and magnetic fields in a WarpX simulation" 
  caption="A WarpX simulation rendered with VisIt on the OLCF Crusher machine (a precursor to Frontier)."%}

**VisIt** is another widely-used post hoc visualization tool, similar to Paraview.  VisIt also developed an OpenPMD reader for WarpX output files, along with GPU capabilities.

ParaView, Ascent and VisIt all leverage the **VTK-m** visualization library to support their GPU capabilities.  

### Programming models and runtimes (S4PST)

Like most high-performance computational science and engineering applications, WarpX uses the Message Passing Interface (MPI), for inter-node parallelism.  **MPICH** and **Open MPI** are implementations of the MPI standard which are used by many supercomputer vendors as the basis of their proprietary MPI implementations and can also be used directly.

### Development tools (STEP)

Competing for a Gordon Bell Prize requires the best possible performance of the application.  Teams often use multiple tools to analyze different aspects of application performance, including **Darshan** for I/O, **HPCToolkit** for profiling, and **TAU** for tracing, and the **Empirical Roofline Toolkit** to understand how the achieved performance compares to the limits of the hardware.  These tools, in turn, rely on tools like **PAPI** to access hardware performance counters, and **Dyninst** to analyze and instrument the executables under study.

{% comment %}
### Advancing software productivity and sustainability

In recent years, the WarpX team has advanced the application software architecture and development practices as needed to address new science challenges. The paper *Then and Now: Improving Software Portability, Productivity, and 100× Performance* DOI:[10.1109/MCSE.2024.3387302](https://doi.org/10.1109/MCSE.2024.3387302) explains WarpX advances in software practices from a perspective of developers of a large-scale science application.
{% endcomment %}

## Additional resources

**WarpX citation:** Fedeli L, Huebl A, Boillod-Cerneux F, Clark T, Gott K, Hillairet C, Jaure S, Leblanc A, Lehe R, Myers A, Piechurski C, Sato M, Zaim N, Zhang W, Vay J-L, Vincenti H. Pushing the Frontier in the Design of Laser-Based Electron Accelerators with Groundbreaking Mesh-Refined Particle-In-Cell Simulations on Exascale-Class Supercomputers. SC22: International Conference for High Performance Computing, Networking, Storage and Analysis (SC). ISSN:2167-4337, pp. 25-36, Dallas, TX, US, 2022. DOI:[10.1109/SC41404.2022.00008](https://doi.org/10.1109/SC41404.2022.00008)

*Authors: Terry Turton, David Bernholdt and Lois Curfman McInnes*<br>
*Acknowledgment: Jean-Luc Vay and the WarpX team*